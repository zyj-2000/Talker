<p align="center">
  <img src="pic/imitator.png" width="100" height="80">
  <h1 align="center"><b>Who is a Better Talker</b></h1>
  <p align="center">Yingjie Zhou Zicheng Zhang, Jun Jia, Yanwei Jiang, Xiaohong Liu, Xiongkuo Min and Guangtao Zhai</p>
  <p align="center">Email: zyj2000@sjtu.edu.cn</p>
</p>

---

## Introduction
This repository explores the fascinating question of imitation capabilities across different models. We investigate various approaches to talking head generation and evaluate their effectiveness in replicating complex talking heads. Our work provides insights into the fundamental differences between imitation learning paradigms.

---

## Visualization
<div align="center">
  <img src="visualization.gif" alt="Motion Imitation Visualization" width="60%">
</div>

*Figure 1: Comparative visualization of different imitation approaches.*

---

## P2P-Motion
Our novel Peer-to-Peer Motion (P2P-Motion) framework establishes a new benchmark in imitation learning. Key features include:
- Real-time motion transfer between heterogeneous agents
- Adaptive spatial-temporal alignment
- Bidirectional imitation capability
- Robustness to morphological differences

---

## Getting Started
To use this Dataset:

[百度云盘：AHQA_Dataset](https://pan.baidu.com/s/1LF8JGvLJWHP7rGQmrHreVQ?pwd=ahqa)

To use sources in Dataset (including Designed Animation and Generated Human Images):

[百度云盘：AHQA_source](https://pan.baidu.com/s/1mOIF--H0Bfv3pvlZKslb9Q?pwd=ahqa)


```bash
git clone https://github.com/yourusername/who-is-a-better-imitator.git
cd who-is-a-better-imitator
pip install -r requirements.txt
